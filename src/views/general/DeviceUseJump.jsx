import React from "react";

export default function DeviceUseJump() {
  return (
    <div>
      <h1>Jump</h1>
      <h2>how to use the device in the jump</h2>
      <h4>
        and other mobile devices now contain diverse and powerful sensors. These
        sensors include GPS sensors, audio sensors (microphones), image sensors
        (cameras), light sensors, direction sensors (compasses), proximity
        sensors, and acceleration sensors (accelerometers). Because of the small
        size of these “smart” mobile devices, their substantial computing power,
        their ability to send and receive data, and their nearly ubiquitous use
        in our society, these devices open up exciting new areas for research in
        data mining and human-computer interaction. The goal of our WISDM
        (WIireless Sensor Data Mining) project (Weiss 2012a) is to explore the
        research and application issues associated with mining sensor data from
        these powerful mobile devices. In this paper we explore the use of the
        smartphone accelerometer sensor to identify the activity a user is
        performing—a task known as activity recognition. We employ a supervised
        learning approach for address- ing the activity recognition task. We
        collect accelerometer data from 59 users as they walk, jog, climb
        stairs, sit, stand, and lie down, and then aggregate this raw time
        series data into examples that cover 10 seconds of activity
      </h4>
    </div>
  );
}
